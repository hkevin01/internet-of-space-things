"""
Resilience Monitor for CubeSat-Enabled Hybrid Survival Network (CEHSN)
Embedded code for sensor mesh health monitoring and self-healing networks
"""

import asyncio
import json
import logging
import statistics
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Dict, List, Optional, Set

logger = logging.getLogger(__name__)


class NodeType(Enum):
    """Types of network nodes"""
    SENSOR = "sensor"
    GATEWAY = "gateway"
    REPEATER = "repeater"
    CUBESAT = "cubesat"
    BASE_STATION = "base_station"
    MOBILE_UNIT = "mobile_unit"


class HealthStatus(Enum):
    """Health status levels"""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    WARNING = "warning"
    CRITICAL = "critical"
    FAILED = "failed"
    UNKNOWN = "unknown"


class AlertLevel(Enum):
    """Alert severity levels"""
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"
    EMERGENCY = "emergency"


class HealingAction(Enum):
    """Types of self-healing actions"""
    RESTART_NODE = "restart_node"
    REROUTE_TRAFFIC = "reroute_traffic"
    ACTIVATE_REDUNDANCY = "activate_redundancy"
    ADJUST_POWER = "adjust_power"
    UPDATE_FIRMWARE = "update_firmware"
    RECALIBRATE_SENSOR = "recalibrate_sensor"
    SWITCH_PROTOCOL = "switch_protocol"
    ISOLATE_NODE = "isolate_node"


@dataclass
class NetworkNode:
    """Represents a node in the resilient network"""
    node_id: str
    node_type: NodeType
    location: Optional[Dict[str, float]] = None  # {"lat": float, "lon": float}
    hardware_version: str = "unknown"
    firmware_version: str = "unknown"
    capabilities: List[str] = field(default_factory=list)
    connections: Set[str] = field(default_factory=set)  # Connected node IDs
    last_seen: datetime = field(default_factory=datetime.utcnow)
    health_status: HealthStatus = HealthStatus.UNKNOWN
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class HealthMetric:
    """Health metric for a network node"""
    node_id: str
    metric_name: str
    value: float
    unit: str
    timestamp: datetime = field(default_factory=datetime.utcnow)
    threshold_warning: Optional[float] = None
    threshold_critical: Optional[float] = None
    is_higher_better: bool = True  # True if higher values are better


@dataclass
class NetworkAlert:
    """Alert generated by the resilience system"""
    alert_id: str
    node_id: str
    alert_level: AlertLevel
    message: str
    details: Dict[str, Any] = field(default_factory=dict)
    suggested_actions: List[HealingAction] = field(default_factory=list)
    timestamp: datetime = field(default_factory=datetime.utcnow)
    acknowledged: bool = False
    resolved: bool = False
    resolution_time: Optional[datetime] = None


@dataclass
class HealingOperation:
    """Self-healing operation record"""
    operation_id: str
    node_id: str
    action: HealingAction
    trigger_alert: str
    parameters: Dict[str, Any] = field(default_factory=dict)
    started_at: datetime = field(default_factory=datetime.utcnow)
    completed_at: Optional[datetime] = None
    success: bool = False
    error_message: Optional[str] = None
    recovery_time_seconds: Optional[float] = None


@dataclass
class NetworkTopology:
    """Current network topology"""
    nodes: Dict[str, NetworkNode] = field(default_factory=dict)
    connections: Dict[str, Set[str]] = field(default_factory=dict)
    redundancy_groups: Dict[str, List[str]] = field(default_factory=dict)
    critical_paths: List[List[str]] = field(default_factory=list)
    last_updated: datetime = field(default_factory=datetime.utcnow)


class ResilienceMonitor:
    """
    Resilience Monitor for self-healing sensor mesh networks
    Monitors network health and automatically triggers recovery actions
    """
    
    def __init__(self, monitor_id: str, network_name: str = "CEHSN"):
        self.monitor_id = monitor_id
        self.network_name = network_name
        self.is_active = False
        
        # Network state
        self.topology = NetworkTopology()
        self.health_history: Dict[str, List[HealthMetric]] = {}
        self.active_alerts: Dict[str, NetworkAlert] = {}
        self.healing_operations: Dict[str, HealingOperation] = {}
        
        # Monitoring configuration
        self.health_check_interval = 30  # seconds
        self.alert_retention_hours = 72
        self.metric_retention_hours = 168  # 1 week
        self.healing_enabled = True
        self.auto_healing_threshold = AlertLevel.WARNING
        
        # Thresholds and rules
        self.default_thresholds = {
            "battery_level": {"warning": 20.0, "critical": 10.0, "higher_better": True},
            "signal_strength": {"warning": -80.0, "critical": -90.0, "higher_better": True},
            "packet_loss": {"warning": 5.0, "critical": 15.0, "higher_better": False},
            "cpu_usage": {"warning": 80.0, "critical": 95.0, "higher_better": False},
            "memory_usage": {"warning": 85.0, "critical": 95.0, "higher_better": False},
            "temperature": {"warning": 70.0, "critical": 85.0, "higher_better": False},
            "uptime_hours": {"warning": 1.0, "critical": 0.5, "higher_better": True}
        }
        
        # Performance metrics
        self.metrics = {
            "nodes_monitored": 0,
            "alerts_generated": 0,
            "healing_operations": 0,
            "successful_healings": 0,
            "average_recovery_time_seconds": 0.0,
            "network_uptime_percent": 100.0
        }
        
        # Background tasks
        self._monitoring_task = None
        self._cleanup_task = None
        
        logger.info(f"Resilience Monitor {monitor_id} initialized for {network_name}")
    
    async def start_monitoring(self) -> bool:
        """Start the resilience monitoring system"""
        try:
            self.is_active = True
            
            # Start background monitoring tasks
            self._monitoring_task = asyncio.create_task(self._monitoring_loop())
            self._cleanup_task = asyncio.create_task(self._cleanup_loop())
            
            logger.info(f"Resilience Monitor {self.monitor_id} started")
            return True
            
        except Exception as e:
            logger.error(f"Failed to start resilience monitor: {e}")
            return False
    
    async def stop_monitoring(self) -> bool:
        """Stop the resilience monitoring system"""
        self.is_active = False
        
        # Cancel background tasks
        if self._monitoring_task:
            self._monitoring_task.cancel()
        if self._cleanup_task:
            self._cleanup_task.cancel()
        
        logger.info(f"Resilience Monitor {self.monitor_id} stopped")
        return True
    
    async def register_node(self, node: NetworkNode) -> bool:
        """Register a new node in the network"""
        try:
            self.topology.nodes[node.node_id] = node
            self.topology.connections[node.node_id] = node.connections.copy()
            self.health_history[node.node_id] = []
            
            # Update topology
            await self._update_network_topology()
            
            self.metrics["nodes_monitored"] = len(self.topology.nodes)
            
            logger.info(f"Registered node {node.node_id} ({node.node_type.value})")
            return True
            
        except Exception as e:
            logger.error(f"Failed to register node {node.node_id}: {e}")
            return False
    
    async def unregister_node(self, node_id: str) -> bool:
        """Unregister a node from the network"""
        try:
            if node_id not in self.topology.nodes:
                logger.warning(f"Node {node_id} not found")
                return False
            
            # Remove node and its connections
            del self.topology.nodes[node_id]
            del self.topology.connections[node_id]
            
            # Remove connections to this node from other nodes
            for other_node_id, connections in self.topology.connections.items():
                connections.discard(node_id)
            
            # Clean up health history
            self.health_history.pop(node_id, None)
            
            # Update topology
            await self._update_network_topology()
            
            self.metrics["nodes_monitored"] = len(self.topology.nodes)
            
            logger.info(f"Unregistered node {node_id}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to unregister node {node_id}: {e}")
            return False
    
    async def report_health_metric(self, metric: HealthMetric) -> bool:
        """Report a health metric for a node"""
        try:
            if metric.node_id not in self.topology.nodes:
                logger.warning(f"Metric for unknown node {metric.node_id}")
                return False
            
            # Add to health history
            if metric.node_id not in self.health_history:
                self.health_history[metric.node_id] = []
            
            self.health_history[metric.node_id].append(metric)
            
            # Update node last seen time
            self.topology.nodes[metric.node_id].last_seen = metric.timestamp
            
            # Check thresholds and generate alerts if needed
            await self._check_metric_thresholds(metric)
            
            # Update node health status
            await self._update_node_health_status(metric.node_id)
            
            return True
            
        except Exception as e:
            logger.error(f"Failed to report health metric: {e}")
            return False
    
    async def report_node_connection(self, node_id: str, connected_nodes: Set[str]) -> bool:
        """Report current connections for a node"""
        try:
            if node_id not in self.topology.nodes:
                logger.warning(f"Connection report for unknown node {node_id}")
                return False
            
            # Update connections
            old_connections = self.topology.connections.get(node_id, set())
            self.topology.connections[node_id] = connected_nodes.copy()
            self.topology.nodes[node_id].connections = connected_nodes.copy()
            
            # Check for connection changes
            new_connections = connected_nodes - old_connections
            lost_connections = old_connections - connected_nodes
            
            if new_connections:
                logger.info(f"Node {node_id} gained connections: {new_connections}")
            
            if lost_connections:
                logger.warning(f"Node {node_id} lost connections: {lost_connections}")
                await self._handle_connection_loss(node_id, lost_connections)
            
            # Update topology
            await self._update_network_topology()
            
            return True
            
        except Exception as e:
            logger.error(f"Failed to report node connection: {e}")
            return False
    
    async def get_network_health(self) -> Dict[str, Any]:
        """Get overall network health status"""
        try:
            total_nodes = len(self.topology.nodes)
            if total_nodes == 0:
                return {"overall_health": "unknown", "nodes": 0}
            
            # Count nodes by health status
            status_counts = {}
            for node in self.topology.nodes.values():
                status = node.health_status.value
                status_counts[status] = status_counts.get(status, 0) + 1
            
            # Calculate overall health score
            health_scores = {
                HealthStatus.HEALTHY: 1.0,
                HealthStatus.DEGRADED: 0.8,
                HealthStatus.WARNING: 0.6,
                HealthStatus.CRITICAL: 0.3,
                HealthStatus.FAILED: 0.0,
                HealthStatus.UNKNOWN: 0.5
            }
            
            total_score = sum(
                status_counts.get(status.value, 0) * score
                for status, score in health_scores.items()
            )
            
            overall_score = total_score / total_nodes
            
            # Determine overall health level
            if overall_score >= 0.9:
                overall_health = "excellent"
            elif overall_score >= 0.7:
                overall_health = "good"
            elif overall_score >= 0.5:
                overall_health = "fair"
            elif overall_score >= 0.3:
                overall_health = "poor"
            else:
                overall_health = "critical"
            
            # Get active alert counts
            alert_counts = {}
            for alert in self.active_alerts.values():
                level = alert.alert_level.value
                alert_counts[level] = alert_counts.get(level, 0) + 1
            
            return {
                "overall_health": overall_health,
                "health_score": overall_score,
                "total_nodes": total_nodes,
                "node_status_counts": status_counts,
                "active_alerts": len(self.active_alerts),
                "alert_counts_by_level": alert_counts,
                "network_connectivity": await self._calculate_network_connectivity(),
                "uptime_percent": self.metrics["network_uptime_percent"],
                "last_updated": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Failed to get network health: {e}")
            return {"overall_health": "error", "error": str(e)}
    
    async def get_node_health(self, node_id: str) -> Optional[Dict[str, Any]]:
        """Get health status for a specific node"""
        try:
            if node_id not in self.topology.nodes:
                return None
            
            node = self.topology.nodes[node_id]
            recent_metrics = self._get_recent_metrics(node_id, hours=1)
            
            # Get latest values for key metrics
            latest_metrics = {}
            for metric in recent_metrics:
                latest_metrics[metric.metric_name] = {
                    "value": metric.value,
                    "unit": metric.unit,
                    "timestamp": metric.timestamp.isoformat()
                }
            
            # Get active alerts for this node
            node_alerts = [
                alert for alert in self.active_alerts.values()
                if alert.node_id == node_id
            ]
            
            return {
                "node_id": node_id,
                "node_type": node.node_type.value,
                "health_status": node.health_status.value,
                "last_seen": node.last_seen.isoformat(),
                "connections": len(node.connections),
                "connected_to": list(node.connections),
                "latest_metrics": latest_metrics,
                "active_alerts": len(node_alerts),
                "location": node.location,
                "hardware_version": node.hardware_version,
                "firmware_version": node.firmware_version
            }
            
        except Exception as e:
            logger.error(f"Failed to get node health for {node_id}: {e}")
            return None
    
    async def acknowledge_alert(self, alert_id: str, acknowledger: str) -> bool:
        """Acknowledge an active alert"""
        try:
            if alert_id not in self.active_alerts:
                logger.warning(f"Alert {alert_id} not found")
                return False
            
            alert = self.active_alerts[alert_id]
            alert.acknowledged = True
            alert.details["acknowledged_by"] = acknowledger
            alert.details["acknowledged_at"] = datetime.utcnow().isoformat()
            
            logger.info(f"Alert {alert_id} acknowledged by {acknowledger}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to acknowledge alert {alert_id}: {e}")
            return False
    
    async def resolve_alert(self, alert_id: str, resolver: str, resolution_note: str = "") -> bool:
        """Mark an alert as resolved"""
        try:
            if alert_id not in self.active_alerts:
                logger.warning(f"Alert {alert_id} not found")
                return False
            
            alert = self.active_alerts[alert_id]
            alert.resolved = True
            alert.resolution_time = datetime.utcnow()
            alert.details["resolved_by"] = resolver
            alert.details["resolution_note"] = resolution_note
            
            logger.info(f"Alert {alert_id} resolved by {resolver}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to resolve alert {alert_id}: {e}")
            return False
    
    async def trigger_healing_operation(self, node_id: str, action: HealingAction,
                                      parameters: Dict[str, Any] = None) -> Optional[str]:
        """Manually trigger a healing operation"""
        try:
            if not self.healing_enabled:
                logger.warning("Healing operations are disabled")
                return None
            
            if node_id not in self.topology.nodes:
                logger.error(f"Node {node_id} not found")
                return None
            
            operation_id = f"heal_{node_id}_{int(datetime.utcnow().timestamp())}"
            
            operation = HealingOperation(
                operation_id=operation_id,
                node_id=node_id,
                action=action,
                trigger_alert="manual_trigger",
                parameters=parameters or {}
            )
            
            self.healing_operations[operation_id] = operation
            
            # Execute the healing operation
            success = await self._execute_healing_operation(operation)
            
            operation.success = success
            operation.completed_at = datetime.utcnow()
            
            if success:
                operation.recovery_time_seconds = (
                    operation.completed_at - operation.started_at
                ).total_seconds()
                self.metrics["successful_healings"] += 1
                
                # Update average recovery time
                self._update_recovery_time_metric(operation.recovery_time_seconds)
            
            self.metrics["healing_operations"] += 1
            
            logger.info(f"Healing operation {operation_id} completed: {success}")
            return operation_id
            
        except Exception as e:
            logger.error(f"Failed to trigger healing operation: {e}")
            return None
    
    def get_monitor_status(self) -> Dict[str, Any]:
        """Get current status of the resilience monitor"""
        return {
            "monitor_id": self.monitor_id,
            "network_name": self.network_name,
            "is_active": self.is_active,
            "healing_enabled": self.healing_enabled,
            "monitoring_interval_seconds": self.health_check_interval,
            "metrics": self.metrics.copy(),
            "topology_summary": {
                "total_nodes": len(self.topology.nodes),
                "node_types": self._get_node_type_counts(),
                "total_connections": sum(len(conns) for conns in self.topology.connections.values()),
                "last_topology_update": self.topology.last_updated.isoformat()
            },
            "alert_summary": {
                "active_alerts": len(self.active_alerts),
                "unacknowledged_alerts": len([a for a in self.active_alerts.values() if not a.acknowledged]),
                "critical_alerts": len([a for a in self.active_alerts.values() if a.alert_level == AlertLevel.CRITICAL])
            }
        }
    
    # Private methods for monitoring and healing
    
    async def _monitoring_loop(self):
        """Main monitoring loop"""
        while self.is_active:
            try:
                await self._check_node_connectivity()
                await self._check_stale_nodes()
                await self._process_pending_healing_operations()
                
                await asyncio.sleep(self.health_check_interval)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Error in monitoring loop: {e}")
                await asyncio.sleep(self.health_check_interval)
    
    async def _cleanup_loop(self):
        """Cleanup loop for old data"""
        while self.is_active:
            try:
                await self._cleanup_old_metrics()
                await self._cleanup_resolved_alerts()
                await self._cleanup_old_healing_operations()
                
                # Run cleanup every hour
                await asyncio.sleep(3600)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Error in cleanup loop: {e}")
                await asyncio.sleep(3600)
    
    async def _check_metric_thresholds(self, metric: HealthMetric):
        """Check if metric violates thresholds and generate alerts"""
        thresholds = self.default_thresholds.get(metric.metric_name)
        if not thresholds:
            return
        
        warning_threshold = metric.threshold_warning or thresholds["warning"]
        critical_threshold = metric.threshold_critical or thresholds["critical"]
        is_higher_better = metric.is_higher_better if hasattr(metric, 'is_higher_better') else thresholds["higher_better"]
        
        alert_level = None
        message = ""
        
        if is_higher_better:
            if metric.value <= critical_threshold:
                alert_level = AlertLevel.CRITICAL
                message = f"{metric.metric_name} critically low: {metric.value} {metric.unit}"
            elif metric.value <= warning_threshold:
                alert_level = AlertLevel.WARNING
                message = f"{metric.metric_name} low: {metric.value} {metric.unit}"
        else:
            if metric.value >= critical_threshold:
                alert_level = AlertLevel.CRITICAL
                message = f"{metric.metric_name} critically high: {metric.value} {metric.unit}"
            elif metric.value >= warning_threshold:
                alert_level = AlertLevel.WARNING
                message = f"{metric.metric_name} high: {metric.value} {metric.unit}"
        
        if alert_level:
            await self._generate_alert(
                metric.node_id,
                alert_level,
                message,
                {"metric": metric.metric_name, "value": metric.value, "unit": metric.unit}
            )
    
    async def _update_node_health_status(self, node_id: str):
        """Update overall health status for a node"""
        if node_id not in self.topology.nodes:
            return
        
        node = self.topology.nodes[node_id]
        recent_metrics = self._get_recent_metrics(node_id, hours=1)
        
        if not recent_metrics:
            node.health_status = HealthStatus.UNKNOWN
            return
        
        # Count alerts by severity
        node_alerts = [
            alert for alert in self.active_alerts.values()
            if alert.node_id == node_id and not alert.resolved
        ]
        
        critical_alerts = len([a for a in node_alerts if a.alert_level == AlertLevel.CRITICAL])
        warning_alerts = len([a for a in node_alerts if a.alert_level == AlertLevel.WARNING])
        
        # Determine health status based on alerts
        if critical_alerts > 0:
            node.health_status = HealthStatus.CRITICAL
        elif warning_alerts > 2:
            node.health_status = HealthStatus.WARNING
        elif warning_alerts > 0:
            node.health_status = HealthStatus.DEGRADED
        else:
            # Check if node is responsive
            time_since_last_seen = datetime.utcnow() - node.last_seen
            if time_since_last_seen > timedelta(minutes=10):
                node.health_status = HealthStatus.FAILED
            elif time_since_last_seen > timedelta(minutes=5):
                node.health_status = HealthStatus.WARNING
            else:
                node.health_status = HealthStatus.HEALTHY
    
    async def _generate_alert(self, node_id: str, level: AlertLevel, message: str,
                            details: Dict[str, Any] = None):
        """Generate a new alert"""
        alert_id = f"alert_{node_id}_{int(datetime.utcnow().timestamp())}"
        
        # Check for duplicate alerts
        similar_alerts = [
            alert for alert in self.active_alerts.values()
            if (alert.node_id == node_id and 
                alert.message == message and 
                not alert.resolved and
                (datetime.utcnow() - alert.timestamp).total_seconds() < 300)  # 5 minutes
        ]
        
        if similar_alerts:
            return  # Don't generate duplicate alerts
        
        alert = NetworkAlert(
            alert_id=alert_id,
            node_id=node_id,
            alert_level=level,
            message=message,
            details=details or {},
            suggested_actions=self._get_suggested_healing_actions(node_id, level, details or {})
        )
        
        self.active_alerts[alert_id] = alert
        self.metrics["alerts_generated"] += 1
        
        logger.warning(f"Generated {level.value} alert for {node_id}: {message}")
        
        # Trigger automatic healing if enabled
        if (self.healing_enabled and 
            level.value in [AlertLevel.WARNING.value, AlertLevel.CRITICAL.value] and
            alert.suggested_actions):
            
            await self._trigger_automatic_healing(alert)
    
    async def _trigger_automatic_healing(self, alert: NetworkAlert):
        """Trigger automatic healing for an alert"""
        if not alert.suggested_actions:
            return
        
        # Use the first suggested action
        action = alert.suggested_actions[0]
        
        operation_id = f"auto_heal_{alert.node_id}_{int(datetime.utcnow().timestamp())}"
        
        operation = HealingOperation(
            operation_id=operation_id,
            node_id=alert.node_id,
            action=action,
            trigger_alert=alert.alert_id,
            parameters={"automatic": True}
        )
        
        self.healing_operations[operation_id] = operation
        
        logger.info(f"Triggering automatic healing: {action.value} for node {alert.node_id}")
        
        # Execute in background
        asyncio.create_task(self._execute_healing_operation_async(operation))
    
    async def _execute_healing_operation_async(self, operation: HealingOperation):
        """Execute healing operation asynchronously"""
        try:
            success = await self._execute_healing_operation(operation)
            
            operation.success = success
            operation.completed_at = datetime.utcnow()
            
            if success:
                operation.recovery_time_seconds = (
                    operation.completed_at - operation.started_at
                ).total_seconds()
                self.metrics["successful_healings"] += 1
                self._update_recovery_time_metric(operation.recovery_time_seconds)
            
            self.metrics["healing_operations"] += 1
            
        except Exception as e:
            operation.error_message = str(e)
            operation.completed_at = datetime.utcnow()
            logger.error(f"Healing operation {operation.operation_id} failed: {e}")
    
    async def _execute_healing_operation(self, operation: HealingOperation) -> bool:
        """Execute a specific healing operation"""
        node_id = operation.node_id
        action = operation.action
        parameters = operation.parameters
        
        try:
            if action == HealingAction.RESTART_NODE:
                return await self._restart_node(node_id, parameters)
            
            elif action == HealingAction.REROUTE_TRAFFIC:
                return await self._reroute_traffic(node_id, parameters)
            
            elif action == HealingAction.ACTIVATE_REDUNDANCY:
                return await self._activate_redundancy(node_id, parameters)
            
            elif action == HealingAction.ADJUST_POWER:
                return await self._adjust_power(node_id, parameters)
            
            elif action == HealingAction.UPDATE_FIRMWARE:
                return await self._update_firmware(node_id, parameters)
            
            elif action == HealingAction.RECALIBRATE_SENSOR:
                return await self._recalibrate_sensor(node_id, parameters)
            
            elif action == HealingAction.SWITCH_PROTOCOL:
                return await self._switch_protocol(node_id, parameters)
            
            elif action == HealingAction.ISOLATE_NODE:
                return await self._isolate_node(node_id, parameters)
            
            else:
                logger.error(f"Unknown healing action: {action}")
                return False
                
        except Exception as e:
            logger.error(f"Error executing healing action {action} on {node_id}: {e}")
            return False
    
    # Healing action implementations (simplified for demonstration)
    
    async def _restart_node(self, node_id: str, parameters: Dict[str, Any]) -> bool:
        """Restart a network node"""
        logger.info(f"Restarting node {node_id}")
        # In a real implementation, this would send restart commands
        await asyncio.sleep(2)  # Simulate restart time
        return True
    
    async def _reroute_traffic(self, node_id: str, parameters: Dict[str, Any]) -> bool:
        """Reroute traffic around a failed node"""
        logger.info(f"Rerouting traffic around node {node_id}")
        # In a real implementation, this would update routing tables
        await asyncio.sleep(1)
        return True
    
    async def _activate_redundancy(self, node_id: str, parameters: Dict[str, Any]) -> bool:
        """Activate redundant systems"""
        logger.info(f"Activating redundancy for node {node_id}")
        # In a real implementation, this would enable backup systems
        await asyncio.sleep(1)
        return True
    
    async def _adjust_power(self, node_id: str, parameters: Dict[str, Any]) -> bool:
        """Adjust power settings"""
        logger.info(f"Adjusting power for node {node_id}")
        # In a real implementation, this would modify power management
        await asyncio.sleep(0.5)
        return True
    
    async def _update_firmware(self, node_id: str, parameters: Dict[str, Any]) -> bool:
        """Update node firmware"""
        logger.info(f"Updating firmware for node {node_id}")
        # In a real implementation, this would trigger firmware update
        await asyncio.sleep(10)  # Firmware updates take longer
        return True
    
    async def _recalibrate_sensor(self, node_id: str, parameters: Dict[str, Any]) -> bool:
        """Recalibrate sensor readings"""
        logger.info(f"Recalibrating sensors for node {node_id}")
        # In a real implementation, this would trigger sensor calibration
        await asyncio.sleep(3)
        return True
    
    async def _switch_protocol(self, node_id: str, parameters: Dict[str, Any]) -> bool:
        """Switch communication protocol"""
        logger.info(f"Switching protocol for node {node_id}")
        # In a real implementation, this would change communication settings
        await asyncio.sleep(1)
        return True
    
    async def _isolate_node(self, node_id: str, parameters: Dict[str, Any]) -> bool:
        """Isolate problematic node"""
        logger.info(f"Isolating node {node_id}")
        # In a real implementation, this would remove node from active network
        if node_id in self.topology.nodes:
            self.topology.nodes[node_id].health_status = HealthStatus.FAILED
        await asyncio.sleep(0.5)
        return True
    
    # Helper methods
    
    def _get_recent_metrics(self, node_id: str, hours: float = 1.0) -> List[HealthMetric]:
        """Get recent metrics for a node"""
        if node_id not in self.health_history:
            return []
        
        cutoff_time = datetime.utcnow() - timedelta(hours=hours)
        
        return [
            metric for metric in self.health_history[node_id]
            if metric.timestamp >= cutoff_time
        ]
    
    def _get_suggested_healing_actions(self, node_id: str, level: AlertLevel,
                                     details: Dict[str, Any]) -> List[HealingAction]:
        """Get suggested healing actions based on alert"""
        actions = []
        
        metric_name = details.get("metric", "")
        
        if "battery" in metric_name.lower():
            actions.extend([HealingAction.ADJUST_POWER, HealingAction.ACTIVATE_REDUNDANCY])
        
        elif "signal" in metric_name.lower():
            actions.extend([HealingAction.SWITCH_PROTOCOL, HealingAction.REROUTE_TRAFFIC])
        
        elif "cpu" in metric_name.lower() or "memory" in metric_name.lower():
            actions.extend([HealingAction.RESTART_NODE, HealingAction.ISOLATE_NODE])
        
        elif "temperature" in metric_name.lower():
            actions.extend([HealingAction.ADJUST_POWER, HealingAction.RESTART_NODE])
        
        else:
            # Default actions
            if level == AlertLevel.CRITICAL:
                actions.extend([HealingAction.RESTART_NODE, HealingAction.ACTIVATE_REDUNDANCY])
            else:
                actions.extend([HealingAction.RECALIBRATE_SENSOR, HealingAction.ADJUST_POWER])
        
        return actions[:2]  # Limit to 2 suggestions
    
    def _get_node_type_counts(self) -> Dict[str, int]:
        """Get count of nodes by type"""
        counts = {}
        for node in self.topology.nodes.values():
            node_type = node.node_type.value
            counts[node_type] = counts.get(node_type, 0) + 1
        return counts
    
    async def _update_network_topology(self):
        """Update network topology information"""
        self.topology.last_updated = datetime.utcnow()
        
        # Update redundancy groups (simplified)
        self.topology.redundancy_groups = self._identify_redundancy_groups()
        
        # Update critical paths
        self.topology.critical_paths = self._identify_critical_paths()
    
    def _identify_redundancy_groups(self) -> Dict[str, List[str]]:
        """Identify groups of nodes that provide redundancy"""
        # Simplified implementation - group by node type and location
        groups = {}
        
        for node in self.topology.nodes.values():
            group_key = f"{node.node_type.value}"
            if node.location:
                # Group by approximate location (simplified)
                lat_rounded = round(node.location.get("lat", 0), 1)
                lon_rounded = round(node.location.get("lon", 0), 1)
                group_key += f"_{lat_rounded}_{lon_rounded}"
            
            if group_key not in groups:
                groups[group_key] = []
            groups[group_key].append(node.node_id)
        
        # Only return groups with multiple nodes
        return {k: v for k, v in groups.items() if len(v) > 1}
    
    def _identify_critical_paths(self) -> List[List[str]]:
        """Identify critical communication paths"""
        # Simplified implementation - find paths between base stations and sensors
        critical_paths = []
        
        base_stations = [
            node_id for node_id, node in self.topology.nodes.items()
            if node.node_type == NodeType.BASE_STATION
        ]
        
        sensors = [
            node_id for node_id, node in self.topology.nodes.items()
            if node.node_type == NodeType.SENSOR
        ]
        
        # For each sensor, find path to nearest base station
        for sensor_id in sensors:
            for base_id in base_stations:
                path = self._find_shortest_path(sensor_id, base_id)
                if path and len(path) > 1:
                    critical_paths.append(path)
                    break  # Only add one path per sensor
        
        return critical_paths
    
    def _find_shortest_path(self, start: str, end: str) -> Optional[List[str]]:
        """Find shortest path between two nodes"""
        # Simplified BFS implementation
        if start not in self.topology.connections or end not in self.topology.connections:
            return None
        
        if start == end:
            return [start]
        
        queue = [(start, [start])]
        visited = {start}
        
        while queue:
            current, path = queue.pop(0)
            
            for neighbor in self.topology.connections.get(current, set()):
                if neighbor == end:
                    return path + [neighbor]
                
                if neighbor not in visited:
                    visited.add(neighbor)
                    queue.append((neighbor, path + [neighbor]))
        
        return None  # No path found
    
    async def _calculate_network_connectivity(self) -> float:
        """Calculate overall network connectivity percentage"""
        total_nodes = len(self.topology.nodes)
        if total_nodes <= 1:
            return 100.0
        
        # Count nodes that can reach at least one base station
        base_stations = [
            node_id for node_id, node in self.topology.nodes.items()
            if node.node_type == NodeType.BASE_STATION
        ]
        
        if not base_stations:
            return 0.0
        
        connected_nodes = 0
        for node_id in self.topology.nodes.keys():
            for base_id in base_stations:
                if self._find_shortest_path(node_id, base_id):
                    connected_nodes += 1
                    break
        
        return (connected_nodes / total_nodes) * 100.0
    
    async def _check_node_connectivity(self):
        """Check connectivity of all nodes"""
        connectivity = await self._calculate_network_connectivity()
        self.metrics["network_uptime_percent"] = connectivity
        
        if connectivity < 80.0:
            await self._generate_alert(
                "network",
                AlertLevel.WARNING,
                f"Network connectivity degraded: {connectivity:.1f}%",
                {"connectivity_percent": connectivity}
            )
    
    async def _check_stale_nodes(self):
        """Check for nodes that haven't reported recently"""
        current_time = datetime.utcnow()
        stale_threshold = timedelta(minutes=10)
        
        for node_id, node in self.topology.nodes.items():
            time_since_last_seen = current_time - node.last_seen
            
            if time_since_last_seen > stale_threshold:
                await self._generate_alert(
                    node_id,
                    AlertLevel.WARNING,
                    f"Node not responding for {time_since_last_seen}",
                    {"last_seen": node.last_seen.isoformat()}
                )
    
    async def _handle_connection_loss(self, node_id: str, lost_connections: Set[str]):
        """Handle loss of connections from a node"""
        if len(lost_connections) > 1:
            await self._generate_alert(
                node_id,
                AlertLevel.CRITICAL,
                f"Node lost multiple connections: {len(lost_connections)}",
                {"lost_connections": list(lost_connections)}
            )
        elif len(lost_connections) == 1:
            await self._generate_alert(
                node_id,
                AlertLevel.WARNING,
                f"Node lost connection to {list(lost_connections)[0]}",
                {"lost_connections": list(lost_connections)}
            )
    
    async def _process_pending_healing_operations(self):
        """Process any pending healing operations"""
        # In a real implementation, this would check for operations that need retry
        pass
    
    def _update_recovery_time_metric(self, recovery_time: float):
        """Update average recovery time metric"""
        current_avg = self.metrics["average_recovery_time_seconds"]
        total_operations = self.metrics["successful_healings"]
        
        if total_operations == 1:
            self.metrics["average_recovery_time_seconds"] = recovery_time
        else:
            self.metrics["average_recovery_time_seconds"] = \
                (current_avg * (total_operations - 1) + recovery_time) / total_operations
    
    # Cleanup methods
    
    async def _cleanup_old_metrics(self):
        """Remove old health metrics"""
        cutoff_time = datetime.utcnow() - timedelta(hours=self.metric_retention_hours)
        
        for node_id in self.health_history:
            self.health_history[node_id] = [
                metric for metric in self.health_history[node_id]
                if metric.timestamp >= cutoff_time
            ]
    
    async def _cleanup_resolved_alerts(self):
        """Remove old resolved alerts"""
        cutoff_time = datetime.utcnow() - timedelta(hours=self.alert_retention_hours)
        
        alerts_to_remove = []
        for alert_id, alert in self.active_alerts.items():
            if (alert.resolved and 
                alert.resolution_time and 
                alert.resolution_time < cutoff_time):
                alerts_to_remove.append(alert_id)
        
        for alert_id in alerts_to_remove:
            del self.active_alerts[alert_id]
    
    async def _cleanup_old_healing_operations(self):
        """Remove old healing operations"""
        cutoff_time = datetime.utcnow() - timedelta(hours=72)  # 3 days
        
        operations_to_remove = []
        for op_id, operation in self.healing_operations.items():
            if (operation.completed_at and 
                operation.completed_at < cutoff_time):
                operations_to_remove.append(op_id)
        
        for op_id in operations_to_remove:
            del self.healing_operations[op_id]
